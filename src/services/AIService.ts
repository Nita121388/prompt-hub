import * as vscode from 'vscode';
import { ConfigurationService } from './ConfigurationService';
import { LocalClaudeProvider } from './LocalClaudeProvider';
import { LocalCodexProvider } from './LocalCodexProvider';

export interface GeneratedMeta {
  name?: string;
  emoji?: string;
}

export type AIProvider = 'openai' | 'azure' | 'gemini' | 'deepseek' | 'qwen' | 'custom' | 'local-claude' | 'local-codex';

/**
 * AI æœåŠ¡ï¼šå°è£…å…ƒä¿¡æ¯ç”Ÿæˆä¸å†…å®¹ä¼˜åŒ–
 * æ”¯æŒå¤šä¸ªæä¾›å•†ï¼šOpenAIã€Azureã€Geminiã€DeepSeekã€Qwenã€è‡ªå®šä¹‰ã€æœ¬åœ° Claude Codeã€æœ¬åœ° Codex
 */
export class AIService {
  private localClaudeProvider: LocalClaudeProvider;
  private localCodexProvider: LocalCodexProvider;

  constructor(private readonly config: ConfigurationService) {
    this.localClaudeProvider = new LocalClaudeProvider(config);
    this.localCodexProvider = new LocalCodexProvider(config);
  }

  private async getApiKey(provider?: AIProvider): Promise<string | undefined> {
    const storageName = provider ? `ai.apiKey.${provider}` : 'ai.apiKey';
    const stored = await this.config.getSecret(storageName);
    if (stored) return stored;
    const input = await vscode.window.showInputBox({
      prompt: `è¾“å…¥ ${provider || 'AI'} API Keyï¼ˆå°†å®‰å…¨ä¿å­˜åœ¨ VSCode SecretStorageï¼‰`,
      password: true,
    });
    if (input) await this.config.storeSecret(storageName, input);
    return input;
  }

  /**
   * æ„å»º API è¯·æ±‚ä½“ï¼ˆæ”¯æŒä¸åŒçš„æä¾›å•†æ ¼å¼ï¼‰
   */
  private buildRequestBody(provider: AIProvider, model: string, temperature: number, messages: any[]): any {
    switch (provider) {
      case 'gemini':
        // Google Gemini API æ ¼å¼
        return {
          model: `models/${model}`,
          generationConfig: {
            temperature,
            topK: 40,
            topP: 0.95,
          },
          contents: messages.map((msg) => ({
            role: msg.role === 'user' ? 'user' : 'model',
            parts: [{ text: msg.content }],
          })),
        };

      case 'deepseek':
        // DeepSeek ä½¿ç”¨ OpenAI å…¼å®¹ API
        return {
          model,
          temperature,
          messages,
        };

      default:
        // OpenAI å…¼å®¹æ ¼å¼ï¼ˆAzureã€Qwenã€Custom éƒ½æ”¯æŒï¼‰
        return {
          model,
          temperature,
          messages,
        };
    }
  }

  /**
   * æ„å»º API ç«¯ç‚¹ URL
   */
  private buildApiUrl(provider: AIProvider, baseUrl?: string): string {
    switch (provider) {
      case 'gemini':
        return 'https://generativelanguage.googleapis.com/v1beta/models';
      case 'deepseek':
        return baseUrl || 'https://api.deepseek.com/chat/completions';
      case 'azure':
        return baseUrl || 'https://{resource-name}.openai.azure.com/openai/deployments/{deployment-id}/chat/completions?api-version=2024-02-15-preview';
      default:
        return `${baseUrl || 'https://api.openai.com'}/v1/chat/completions`;
    }
  }

  /**
   * è§£æ API å“åº”ï¼ˆå¤„ç†ä¸åŒæä¾›å•†çš„å“åº”æ ¼å¼ï¼‰
   */
  private parseResponse(provider: AIProvider, data: any): string {
    switch (provider) {
      case 'gemini':
        // Gemini å“åº”æ ¼å¼
        return data.candidates?.[0]?.content?.parts?.[0]?.text?.trim() || '';
      default:
        // OpenAI å…¼å®¹æ ¼å¼
        return data.choices?.[0]?.message?.content?.trim() || '';
    }
  }

  /**
   * æ„å»ºè¯·æ±‚å¤´
   */
  private buildHeaders(provider: AIProvider, apiKey: string): Record<string, string> {
    const headers: Record<string, string> = {
      'Content-Type': 'application/json',
    };

    switch (provider) {
      case 'gemini':
        // Gemini ä½¿ç”¨ API Key ä½œä¸ºæŸ¥è¯¢å‚æ•°ï¼Œä½†ä»éœ€åœ¨ header ä¸­æä¾›
        headers['X-API-Key'] = apiKey;
        break;
      case 'azure':
        // Azure ä½¿ç”¨ç‰¹æ®Šçš„ header
        headers['api-key'] = apiKey;
        break;
      default:
        // OpenAI å…¼å®¹æ ¼å¼
        headers['Authorization'] = `Bearer ${apiKey}`;
        break;
    }

    return headers;
  }

  async generateMeta(content: string): Promise<GeneratedMeta> {
    const provider = this.config.get<AIProvider>('ai.provider', 'openai');
    const supportedProviders: AIProvider[] = ['openai', 'azure', 'gemini', 'deepseek', 'qwen', 'custom', 'local-claude', 'local-codex'];

    if (!supportedProviders.includes(provider)) {
      void vscode.window.showWarningMessage(`ä¸æ”¯æŒçš„ AI æä¾›å•†ï¼š${provider}`);
      // é™çº§å¤„ç†
      const line = content.split('\n')[0].trim().slice(0, 40);
      return { name: line || 'æœªå‘½å', emoji: 'ğŸ“' };
    }

    // æœ¬åœ° Claude Code
    if (provider === 'local-claude') {
      try {
        return await this.localClaudeProvider.generateMeta(content);
      } catch (error) {
        void vscode.window.showWarningMessage(`æœ¬åœ° Claude Code è°ƒç”¨å¤±è´¥ï¼š${(error as Error).message}`);
        return this.fallbackMeta(content);
      }
    }

    // æœ¬åœ° Codex
    if (provider === 'local-codex') {
      try {
        return await this.localCodexProvider.generateMeta(content);
      } catch (error) {
        void vscode.window.showWarningMessage(`æœ¬åœ° Codex è°ƒç”¨å¤±è´¥ï¼š${(error as Error).message}`);
        return this.fallbackMeta(content);
      }
    }

    // äº‘ç«¯ API è°ƒç”¨
    try {
      const apiKey = await this.getApiKey(provider);
      if (!apiKey) throw new Error('æœªé…ç½® API Key');

      const baseUrl = this.config.get<string>('ai.baseUrl', this.buildApiUrl(provider));
      const model = this.config.get<string>('ai.model', this.getDefaultModel(provider));
      const temperature = this.config.get<number>('ai.temperature', 0.4);

      const systemPrompt = 'ä½ æ˜¯ä¸€ä¸ªæç¤ºè¯æ•´ç†åŠ©æ‰‹ã€‚æ ¹æ®ç”¨æˆ·æä¾›çš„æ–‡æœ¬ï¼Œè¿”å›ä¸€ä¸ª JSONï¼š{"name":"ç®€çŸ­æ ‡é¢˜","emoji":"ä¸€ä¸ªåˆé€‚çš„emoji"}ã€‚ä»…è¾“å‡º JSONã€‚';
      const userContent = content.substring(0, 4000);

      const requestBody = this.buildRequestBody(provider, model, temperature, [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userContent },
      ]);

      const url = provider === 'gemini' ? `${baseUrl}:generateContent?key=${apiKey}` : baseUrl;
      const headers = this.buildHeaders(provider, apiKey);

      const res = await fetch(url, {
        method: 'POST',
        headers,
        body: JSON.stringify(requestBody),
      });

      if (!res.ok) throw new Error(`HTTP ${res.status}: ${res.statusText}`);

      const data: any = await res.json();
      const text = this.parseResponse(provider, data);

      try {
        const parsed = JSON.parse(text);
        return { name: parsed.name, emoji: parsed.emoji };
      } catch {
        // ç®€å•é™çº§ï¼šå–ç¬¬ä¸€è¡Œä½œä¸ºæ ‡é¢˜
        const line = content.split('\n')[0].trim().slice(0, 40);
        return { name: line || 'æœªå‘½å', emoji: 'ğŸ“' };
      }
    } catch (e) {
      void vscode.window.showWarningMessage(`AI å…ƒä¿¡æ¯ç”Ÿæˆå¤±è´¥ï¼š${(e as Error).message}`);
      // é™çº§å¤„ç†
      const line = content.split('\n')[0].trim().slice(0, 40);
      return { name: line || 'æœªå‘½å', emoji: 'ğŸ“' };
    }
  }

  async optimize(content: string): Promise<string> {
    const provider = this.config.get<AIProvider>('ai.provider', 'openai');
    const supportedProviders: AIProvider[] = ['openai', 'azure', 'gemini', 'deepseek', 'qwen', 'custom', 'local-claude', 'local-codex'];

    if (!supportedProviders.includes(provider)) {
      void vscode.window.showWarningMessage(`ä¸æ”¯æŒçš„ AI æä¾›å•†ï¼š${provider}`);
      return content;
    }

    // æœ¬åœ° Claude Code
    if (provider === 'local-claude') {
      try {
        return await this.localClaudeProvider.optimize(content);
      } catch (error) {
        void vscode.window.showWarningMessage(`æœ¬åœ° Claude Code ä¼˜åŒ–å¤±è´¥ï¼š${(error as Error).message}`);
        return content;
      }
    }

    // æœ¬åœ° Codex
    if (provider === 'local-codex') {
      try {
        return await this.localCodexProvider.optimize(content);
      } catch (error) {
        void vscode.window.showWarningMessage(`æœ¬åœ° Codex ä¼˜åŒ–å¤±è´¥ï¼š${(error as Error).message}`);
        return content;
      }
    }

    // äº‘ç«¯ API è°ƒç”¨
    try {
      const apiKey = await this.getApiKey(provider);
      if (!apiKey) throw new Error('æœªé…ç½® API Key');

      const baseUrl = this.config.get<string>('ai.baseUrl', this.buildApiUrl(provider));
      const model = this.config.get<string>('ai.model', this.getDefaultModel(provider));
      const temperature = this.config.get<number>('ai.temperature', 0.3);

      const systemPrompt = 'ä½ æ˜¯ä¸€ä¸ªæç¤ºè¯ä¼˜åŒ–åŠ©æ‰‹ã€‚è¯·å°†æç¤ºè¯æ¶¦è‰²ä¸ºæ¸…æ™°ã€ç®€çŸ­ã€æœ‰æ¡ç†çš„ä¸­æ–‡ Markdown æ–‡æœ¬ï¼Œä¿ç•™åŸæ„ã€‚åªè¿”å›ä¼˜åŒ–åçš„æ–‡æœ¬ã€‚';
      const userContent = content.substring(0, 8000);

      const requestBody = this.buildRequestBody(provider, model, temperature, [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userContent },
      ]);

      const url = provider === 'gemini' ? `${baseUrl}:generateContent?key=${apiKey}` : baseUrl;
      const headers = this.buildHeaders(provider, apiKey);

      const res = await fetch(url, {
        method: 'POST',
        headers,
        body: JSON.stringify(requestBody),
      });

      if (!res.ok) throw new Error(`HTTP ${res.status}: ${res.statusText}`);

      const data: any = await res.json();
      const text = this.parseResponse(provider, data);

      return text || content;
    } catch (e) {
      void vscode.window.showWarningMessage(`AI ä¼˜åŒ–å¤±è´¥ï¼š${(e as Error).message}`);
      return content;
    }
  }

  /**
   * é™çº§å¤„ç†ï¼šä»å†…å®¹ç¬¬ä¸€è¡Œç”Ÿæˆå…ƒä¿¡æ¯
   */
  private fallbackMeta(content: string): GeneratedMeta {
    const line = content.split('\n')[0].trim().slice(0, 40);
    return { name: line || 'æœªå‘½å', emoji: 'ğŸ“' };
  }

  /**
   * è·å–æä¾›å•†çš„é»˜è®¤æ¨¡å‹
   */
  private getDefaultModel(provider: AIProvider): string {
    switch (provider) {
      case 'gemini':
        return 'gemini-1.5-pro';
      case 'deepseek':
        return 'deepseek-chat';
      case 'azure':
        return 'gpt-4o';
      case 'qwen':
        return 'qwen-max';
      case 'local-claude':
        return 'claude-sonnet-4.5';
      case 'local-codex':
        return 'claude-sonnet-4.5';
      default:
        return 'gpt-4o';
    }
  }
}

